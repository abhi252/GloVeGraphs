{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import gensim\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Citation Network for Testing. The dataset has papers between the years 1992 - 2002. Papers published between 1992 and 1995 will be taken separately as a new training graph. \n",
    "\n",
    "# Papers generated between 1996-1997 will be used for testing. Edges belonging to papers published in those years are removed at random (which are stored separately and kept). We will use this as the test set and evaluate the performance of node2vec and glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Build training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import text file containing edge list and write to dictionary\n",
    "dict_edges = defaultdict(int)\n",
    "\n",
    "with open('graph/cit-HepTh.txt') as f:\n",
    "    for line in f:\n",
    "        cols = line.split()\n",
    "        if(len(cols)>2):\n",
    "            continue\n",
    "        dict_edges[cols[0]+\"-\"+cols[1]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print '#-FromNodeId' in dict_edges.keys()\n",
    "print '#-Directed' in dict_edges.keys()\n",
    "print '9504145-9309097' in dict_edges.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317526\n"
     ]
    }
   ],
   "source": [
    "# Get 90% of edges and store in training data \n",
    "\n",
    "len_training_set = int(0.9*len(dict_edges.keys()))\n",
    "print len_training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set = random.sample(dict_edges.keys(),len_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dict = {}\n",
    "for edge in training_set:\n",
    "    training_dict[edge] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set = {}\n",
    "\n",
    "for edge in dict_edges.keys():\n",
    "    if edge in training_dict:\n",
    "        continue\n",
    "    else:\n",
    "        test_set[edge] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "len_test_set = len(test_set)\n",
    "print len(dict_edges.keys())-len_training_set-len_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nodes without an edge between them to training set\n",
    "filehandle = open('graph/cit-HepTh.txt','rb')\n",
    "data = filehandle.readlines()\n",
    "G = nx.DiGraph()\n",
    "for x in data:\n",
    "    temp = str(x)\n",
    "    temp = temp.split()\n",
    "    G.add_edge(temp[0],temp[1])\n",
    "    \n",
    "node_list = G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep sampling pairs of nodes until we get half the length of training set pairs of nodes without edges between them \n",
    "dict_node_no_edge = defaultdict(int)\n",
    "counter = 0\n",
    "loop_index = 0\n",
    "while(loop_index <= len_training_set):\n",
    "    node_pair = random.sample(node_list,2)\n",
    "    if str(node_pair[0])+'-'+str(node_pair[1]) in dict_edges or str(node_pair[0])+'-'+str(node_pair[1]) in dict_node_no_edge:\n",
    "        continue\n",
    "    else:\n",
    "        dict_node_no_edge[str(node_pair[0])+'-'+str(node_pair[1])]=0\n",
    "        counter += 1\n",
    "        if(counter >= int(len_training_set/2)):\n",
    "            break\n",
    "    loop_index += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158762"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node_pair in dict_node_no_edge:\n",
    "    nodes = node_pair.split('-')\n",
    "    if G.has_edge(nodes[0],nodes[1]):\n",
    "        print \"Exception! Breaking\"\n",
    "        break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_append = random.sample(dict_node_no_edge.keys(),int(0.9*len(dict_node_no_edge.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for edge in training_set_append:\n",
    "    training_dict[edge] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in dict_node_no_edge.keys():\n",
    "    if edge in training_dict or edge in test_set:\n",
    "        continue\n",
    "    else:\n",
    "        test_set[edge] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51158"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460412"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('training_data.txt', 'wb') as handle:\n",
    "  pickle.dump(training_dict, handle)\n",
    "\n",
    "with open('testing_data.txt', 'wb') as handle_1:\n",
    "  pickle.dump(test_set, handle_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
